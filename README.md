# AI Aggregator

Ğ£Ğ½Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ° Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ AI-Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ°Ğ¼Ğ¸ (OpenAI, Claude, Ollama) Ñ‡ĞµÑ€ĞµĞ· ĞµĞ´Ğ¸Ğ½Ñ‹Ğ¹ GraphQL API.

## âœ¨ Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸

- ğŸš€ **ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°** â€” ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ AI-Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ñ Ñ„Ğ¾Ğ½Ğ¾Ğ²Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¾Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Redis/asynq
- ğŸ”„ **ĞœÑƒĞ»ÑŒÑ‚Ğ¸-Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ñ‹** â€” OpenAI, Claude, Ollama, Stub (Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¾Ğ²)
- ğŸ“Š **ĞÑ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ** â€” Ñ‚Ğ¾ĞºĞµĞ½Ñ‹, ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ°Ğ¼ Ğ¸ Ñ‚ĞµĞ½Ğ°Ğ½Ñ‚Ğ°Ğ¼
- ğŸ” **API-ĞºĞ»ÑÑ‡Ğ¸** â€” Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ñ‚ĞµĞ½Ğ°Ğ½Ñ‚Ğ½Ğ°Ñ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ
- ğŸ® **GraphQL Playground** â€” Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ API

## ğŸ—ï¸ ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GraphQL API   â”‚     â”‚     Worker       â”‚
â”‚    (:8080)      â”‚     â”‚   (asynq)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚  PostgreSQL â”‚
              â”‚   (jobs)    â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚    Redis    â”‚
              â”‚   (queue)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ ÑÑ‚Ğ°Ñ€Ñ‚

### 1. Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹

```bash
docker compose up -d postgres redis
```

### 2. ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¹

```bash
./scripts/migrate.sh
```

### 3. Ğ—Ğ°Ğ¿ÑƒÑĞº API ÑĞµÑ€Ğ²ĞµÑ€Ğ°

```bash
lsof -ti:8080 | xargs kill -9 2>/dev/null; sleep 1 && go run ./apps/api/cmd/server
```

### 4. Ğ—Ğ°Ğ¿ÑƒÑĞº Worker (Ğ² Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğ¼ Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ°Ğ»Ğµ)

```bash
go run ./apps/worker/cmd/worker
```

### 5. Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

```bash
# GraphQL Playground
open http://localhost:8080/playground

# Ğ˜Ğ»Ğ¸ Ñ‡ĞµÑ€ĞµĞ· curl
curl -X POST http://localhost:8080/graphql \
  -H "Content-Type: application/json" \
  -H "X-API-Key: dev-api-key-12345" \
  -d '{"query":"mutation { createJob(input: { type: TEXT, input: \"Hello AI!\" }) { id status } }"}'
```

## ğŸ’» ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ ĞºĞ¾Ğ´Ğ°

### Chat Completions (ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚)

```bash
curl -X POST http://localhost:8080/api/chat/completions \
  -H "X-API-Key: YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "ĞĞ±ÑŠÑÑĞ½Ğ¸ Ñ‡Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ REST API",
    "provider": "openai",
    "model": "gpt-4o-mini"
  }'
```

**ĞÑ‚Ğ²ĞµÑ‚:**
```json
{
  "content": "REST API â€” ÑÑ‚Ğ¾ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ğ¹ ÑÑ‚Ğ¸Ğ»ÑŒ...",
  "finishReason": "stop",
  "tokensIn": 14,
  "tokensOut": 156,
  "cost": 0.0000552,
  "provider": "openai",
  "model": "gpt-4o-mini"
}
```

### Chat Ñ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸ĞµĞ¹ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹

```bash
curl -X POST http://localhost:8080/api/chat/completions \
  -H "X-API-Key: YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "system", "content": "Ğ¢Ñ‹ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚"},
      {"role": "user", "content": "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚!"},
      {"role": "assistant", "content": "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ§ĞµĞ¼ Ğ¼Ğ¾Ğ³Ñƒ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ?"},
      {"role": "user", "content": "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ½Ğ° Python"}
    ],
    "provider": "openai",
    "model": "gpt-4o-mini"
  }'
```

### SSE Streaming (real-time Ğ¾Ñ‚Ğ²ĞµÑ‚)

```bash
curl -N http://localhost:8080/stream \
  -H "X-API-Key: YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ ÑÑ‚Ğ¸Ñ…Ğ¾Ñ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ¾ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸",
    "provider": "openai",
    "model": "gpt-4o-mini"
  }'
```

### JavaScript/TypeScript

```typescript
// Chat Completions
const response = await fetch('http://localhost:8080/api/chat/completions', {
  method: 'POST',
  headers: {
    'X-API-Key': 'YOUR_API_KEY',
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    prompt: 'ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! ĞšĞ°Ğº Ğ´ĞµĞ»Ğ°?',
    provider: 'openai',
    model: 'gpt-4o-mini',
  }),
});

const data = await response.json();
console.log(data.content);
```

```typescript
// SSE Streaming
const response = await fetch('http://localhost:8080/stream', {
  method: 'POST',
  headers: {
    'X-API-Key': 'YOUR_API_KEY',
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({ prompt: 'Hello!' }),
});

const reader = response.body?.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader!.read();
  if (done) break;

  const chunk = decoder.decode(value);
  const lines = chunk.split('\n').filter(line => line.startsWith('data: '));

  for (const line of lines) {
    const data = JSON.parse(line.slice(6));
    if (data.type === 'chunk') {
      process.stdout.write(data.content);
    }
  }
}
```

### Python

```python
import requests

# Chat Completions
response = requests.post(
    'http://localhost:8080/api/chat/completions',
    headers={
        'X-API-Key': 'YOUR_API_KEY',
        'Content-Type': 'application/json',
    },
    json={
        'prompt': 'ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! ĞšĞ°Ğº Ğ´ĞµĞ»Ğ°?',
        'provider': 'openai',
        'model': 'gpt-4o-mini',
    }
)

data = response.json()
print(data['content'])
```

```python
# SSE Streaming
import sseclient

response = requests.post(
    'http://localhost:8080/stream',
    headers={'X-API-Key': 'YOUR_API_KEY', 'Content-Type': 'application/json'},
    json={'prompt': 'Hello!'},
    stream=True
)

client = sseclient.SSEClient(response)
for event in client.events():
    data = json.loads(event.data)
    if data.get('type') == 'chunk':
        print(data['content'], end='', flush=True)
```

### Go

```go
package main

import (
    "bytes"
    "encoding/json"
    "fmt"
    "net/http"
)

func main() {
    payload := map[string]interface{}{
        "prompt":   "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! ĞšĞ°Ğº Ğ´ĞµĞ»Ğ°?",
        "provider": "openai",
        "model":    "gpt-4o-mini",
    }

    body, _ := json.Marshal(payload)
    req, _ := http.NewRequest("POST", "http://localhost:8080/api/chat/completions", bytes.NewBuffer(body))
    req.Header.Set("X-API-Key", "YOUR_API_KEY")
    req.Header.Set("Content-Type", "application/json")

    resp, _ := http.DefaultClient.Do(req)
    defer resp.Body.Close()

    var result map[string]interface{}
    json.NewDecoder(resp.Body).Decode(&result)
    fmt.Println(result["content"])
}
```

## ğŸ“ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°

```
AIAggregator/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ api/              # GraphQL API ÑĞµÑ€Ğ²ĞµÑ€
â”‚   â”‚   â”œâ”€â”€ cmd/server/   # Ğ¢Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ°
â”‚   â”‚   â””â”€â”€ internal/
â”‚   â”‚       â”œâ”€â”€ graph/    # GraphQL resolvers (gqlgen)
â”‚   â”‚       â”œâ”€â”€ handlers/ # HTTP handlers
â”‚   â”‚       â””â”€â”€ middleware/
â”‚   â”œâ”€â”€ worker/           # Asynq worker
â”‚   â””â”€â”€ web/              # Next.js Ñ„Ñ€Ğ¾Ğ½Ñ‚ĞµĞ½Ğ´ (WIP)
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ domain/           # Ğ”Ğ¾Ğ¼ĞµĞ½Ğ½Ñ‹Ğµ ÑÑƒÑ‰Ğ½Ğ¾ÑÑ‚Ğ¸ (Job, Tenant, Usage)
â”‚   â”œâ”€â”€ usecases/         # Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° (JobService, AuthService)
â”‚   â”œâ”€â”€ providers/        # AI Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ñ‹ (OpenAI, Claude, Stub)
â”‚   â”œâ”€â”€ adapters/         # Ğ ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¸ (PostgreSQL, InMemory)
â”‚   â”œâ”€â”€ queue/            # ĞÑ‡ĞµÑ€ĞµĞ´ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡ (asynq)
â”‚   â””â”€â”€ shared/           # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ, Ğ»Ğ¾Ğ³Ğ³ĞµÑ€
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ postgres/
â”‚   â”‚   â”œâ”€â”€ migrations/   # SQL Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸
â”‚   â”‚   â”œâ”€â”€ queries/      # sqlc queries
â”‚   â”‚   â””â”€â”€ db/           # Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ sqlc ĞºĞ¾Ğ´
â”‚   â””â”€â”€ docker/           # Dockerfiles
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ gqlgen.yml
â””â”€â”€ go.mod
```

## âš™ï¸ ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ

Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ `.env` Ñ„Ğ°Ğ¹Ğ» (ÑĞ¼. `.env.example`):

```env
# Server
API_HOST=0.0.0.0
API_PORT=8080

# Database
DATABASE_URL=postgres://postgres:postgres@localhost:5432/aiaggregator?sslmode=disable

# Redis
REDIS_URL=redis://localhost:6379

# AI Providers (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
OLLAMA_URL=http://localhost:11434

# Features
ENABLE_PLAYGROUND=true
LOG_LEVEL=debug
```

## ğŸ”Œ GraphQL API

### Queries

```graphql
# Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ñ‚ĞµĞ½Ğ°Ğ½Ñ‚
query { me { id name active } }

# ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ job Ğ¿Ğ¾ ID
query { job(id: "...") { id status result provider tokensIn tokensOut cost } }

# Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº jobs
query { jobs { edges { node { id status type } } pageInfo { totalCount } } }

# Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ¾Ğ²
query { providers { id name type enabled } }
```

### Mutations

```graphql
# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ job
mutation {
  createJob(input: { type: TEXT, input: "Ğ Ğ°ÑÑĞºĞ°Ğ¶Ğ¸ Ğ¿Ñ€Ğ¾ Go" }) {
    id status
  }
}

# ĞÑ‚Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ job
mutation { cancelJob(id: "...") { id status } }
```

## ğŸ”§ Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°

### Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ GraphQL

```bash
cd apps/api && ~/go/bin/gqlgen generate
```

### Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ sqlc

```bash
cd infrastructure/postgres && ~/go/bin/sqlc generate
```

### Ğ¡Ğ±Ğ¾Ñ€ĞºĞ°

```bash
go build ./...
```

### Ğ¢ĞµÑÑ‚Ñ‹

```bash
go test ./...
```

## ğŸ“¦ Ğ¢ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸

| ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚ | Ğ¢ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ |
|-----------|------------|
| Backend | Go 1.24+ |
| GraphQL | gqlgen |
| Database | PostgreSQL 16 |
| ORM | sqlc |
| Queue | Redis + asynq |
| Frontend | Next.js 14 (WIP) |

## ğŸ“ License

MIT

---

## License

MIT
